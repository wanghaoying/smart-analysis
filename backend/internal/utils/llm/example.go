package llm

import (
	"context"
	"fmt"
	"log"
	"smart-analysis/internal/config"
)

// exampleUsage å±•ç¤ºå¦‚ä½•ä½¿ç”¨LLMç®¡ç†å™¨è¿›è¡ŒèŠå¤©
func exampleUsage() {
	// 1. åŠ è½½åº”ç”¨é…ç½®
	appConfig := config.Load()

	// 2. åˆå§‹åŒ–å…¨å±€ç®¡ç†å™¨
	if err := InitializeGlobalManager(appConfig); err != nil {
		log.Fatalf("Failed to initialize LLM manager: %v", err)
	}

	// 3. è·å–ç®¡ç†å™¨å®ä¾‹
	manager := GetGlobalManager()

	// 4. æ£€æŸ¥å¯ç”¨çš„æä¾›å•†
	providers := manager.ListProviders()
	fmt.Printf("Available providers: %v\n", providers)

	// 5. åˆ›å»ºèŠå¤©è¯·æ±‚
	req := &ChatRequest{
		Messages: []Message{
			{Role: "system", Content: "You are a helpful assistant."},
			{Role: "user", Content: "Hello, how are you?"},
		},
		Model:       "", // ä½¿ç”¨é»˜è®¤æ¨¡å‹
		MaxTokens:   100,
		Temperature: 0.7,
	}

	ctx := context.Background()

	// 6. ä½¿ç”¨é»˜è®¤å®¢æˆ·ç«¯è¿›è¡Œé˜»å¡å¼èŠå¤©
	fmt.Println("\n=== Blocking Chat Example ===")
	resp, err := manager.ChatWithDefault(ctx, req)
	if err != nil {
		log.Printf("Chat error: %v", err)
	} else {
		if resp.Error != nil {
			log.Printf("API error: %s", resp.Error.Message)
		} else if len(resp.Choices) > 0 {
			fmt.Printf("Response: %s\n", resp.Choices[0].Message.Content)
		}
	}

	// 7. ä½¿ç”¨é»˜è®¤å®¢æˆ·ç«¯è¿›è¡Œæµå¼èŠå¤©
	fmt.Println("\n=== Streaming Chat Example ===")
	eventChan, err := manager.StreamChatWithDefault(ctx, req)
	if err != nil {
		log.Printf("Stream chat error: %v", err)
		return
	}

	fmt.Print("Streaming response: ")
	for event := range eventChan {
		if event.Error != nil {
			log.Printf("Stream error: %v", event.Error)
			break
		}

		if event.Data != nil {
			if event.Data.Error != nil {
				log.Printf("API error: %s", event.Data.Error.Message)
				break
			}

			if len(event.Data.Choices) > 0 && event.Data.Choices[0].Delta != nil {
				fmt.Print(event.Data.Choices[0].Delta.Content)
			}
		}

		if event.Done {
			fmt.Println("\n[Stream completed]")
			break
		}
	}

	// 8. ä½¿ç”¨ç‰¹å®šæä¾›å•†
	if len(providers) > 0 {
		fmt.Printf("\n=== Using specific provider: %s ===\n", providers[0])
		resp, err := manager.Chat(ctx, providers[0], req)
		if err != nil {
			log.Printf("Provider chat error: %v", err)
		} else {
			if resp.Error != nil {
				log.Printf("API error: %s", resp.Error.Message)
			} else if len(resp.Choices) > 0 {
				fmt.Printf("Response: %s\n", resp.Choices[0].Message.Content)
			}
		}
	}
}

// exampleManualSetup å±•ç¤ºæ‰‹åŠ¨è®¾ç½®å®¢æˆ·ç«¯çš„æ–¹æ³•
func exampleManualSetup() {
	// åˆ›å»ºç®¡ç†å™¨
	manager := NewClientManager()

	// æ‰‹åŠ¨é…ç½®OpenAI
	openaiConfig := &Config{
		Provider:    ProviderOpenAI,
		APIKey:      "your-openai-api-key",
		BaseURL:     "https://api.openai.com/v1",
		Model:       "gpt-3.5-turbo",
		MaxTokens:   1000,
		Temperature: 0.7,
		Timeout:     60,
	}

	if err := manager.RegisterProvider(ProviderOpenAI, openaiConfig); err != nil {
		log.Printf("Failed to register OpenAI: %v", err)
	}

	// æ‰‹åŠ¨é…ç½®æ··å…ƒ
	hunyuanConfig := &Config{
		Provider:    ProviderHunyuan,
		APIKey:      "secretId:secretKey", // æ›¿æ¢ä¸ºå®é™…çš„å¯†é’¥
		BaseURL:     "https://hunyuan.tencentcloudapi.com",
		Model:       "hunyuan-lite",
		MaxTokens:   1000,
		Temperature: 0.7,
		Timeout:     60,
	}

	if err := manager.RegisterProvider(ProviderHunyuan, hunyuanConfig); err != nil {
		log.Printf("Failed to register Hunyuan: %v", err)
	}

	// ä½¿ç”¨å®¢æˆ·ç«¯
	ctx := context.Background()
	req := &ChatRequest{
		Messages: []Message{
			{Role: "user", Content: "Hello!"},
		},
	}

	// æµ‹è¯•OpenAI
	if resp, err := manager.Chat(ctx, ProviderOpenAI, req); err != nil {
		log.Printf("OpenAI error: %v", err)
	} else {
		fmt.Printf("OpenAI response: %s\n", resp.Choices[0].Message.Content)
	}

	// æµ‹è¯•æ··å…ƒ
	if resp, err := manager.Chat(ctx, ProviderHunyuan, req); err != nil {
		log.Printf("Hunyuan error: %v", err)
	} else {
		fmt.Printf("Hunyuan response: %s\n", resp.Choices[0].Message.Content)
	}

	// æ¸…ç†èµ„æº
	if err := manager.Close(); err != nil {
		log.Printf("Failed to close manager: %v", err)
	}
}

// exampleWithDifferentConfigs å±•ç¤ºä¸åŒé…ç½®çš„ä½¿ç”¨
func exampleWithDifferentConfigs() {
	manager := NewClientManager()

	// é«˜åˆ›é€ æ€§é…ç½®
	creativeConfig := &Config{
		Provider:    ProviderOpenAI,
		APIKey:      "your-api-key",
		Model:       "gpt-4",
		MaxTokens:   2000,
		Temperature: 1.2, // é«˜åˆ›é€ æ€§
		Timeout:     120,
	}

	// ä¿å®ˆé…ç½®
	conservativeConfig := &Config{
		Provider:    ProviderOpenAI,
		APIKey:      "your-api-key",
		Model:       "gpt-3.5-turbo",
		MaxTokens:   500,
		Temperature: 0.1, // ä½åˆ›é€ æ€§
		Timeout:     30,
	}

	// æ³¨å†Œä¸åŒé…ç½®ï¼ˆæ³¨æ„ï¼šå®é™…ä½¿ç”¨ä¸­åŒä¸€provideråªèƒ½æ³¨å†Œä¸€æ¬¡ï¼‰
	_ = creativeConfig
	_ = conservativeConfig
	_ = manager

	fmt.Println("Different configurations can be used for different scenarios")
}

func example() {
	// åˆ›å»ºå®¢æˆ·ç«¯ç®¡ç†å™¨
	manager := NewClientManager()

	// é…ç½®OpenAIï¼ˆå¦‚æœæœ‰API Keyçš„è¯ï¼‰
	if apiKey := "your-openai-api-key"; apiKey != "" && apiKey != "your-openai-api-key" {
		openaiConfig := &Config{
			Provider:    ProviderOpenAI,
			APIKey:      apiKey,
			Model:       "gpt-3.5-turbo",
			MaxTokens:   1000,
			Temperature: 0.7,
			Timeout:     60,
		}

		if err := manager.RegisterProvider(ProviderOpenAI, openaiConfig); err != nil {
			log.Printf("Failed to register OpenAI: %v", err)
		} else {
			fmt.Println("âœ… OpenAI client registered successfully")
		}
	}

	// é…ç½®æ··å…ƒï¼ˆå¦‚æœæœ‰API Keyçš„è¯ï¼‰
	if apiKey := "your-secret-id:your-secret-key"; apiKey != "" && apiKey != "your-secret-id:your-secret-key" {
		hunyuanConfig := &Config{
			Provider:    ProviderHunyuan,
			APIKey:      apiKey,
			Model:       "hunyuan-lite",
			MaxTokens:   1000,
			Temperature: 0.7,
			Timeout:     60,
		}

		if err := manager.RegisterProvider(ProviderHunyuan, hunyuanConfig); err != nil {
			log.Printf("Failed to register Hunyuan: %v", err)
		} else {
			fmt.Println("âœ… Hunyuan client registered successfully")
		}
	}

	// æ£€æŸ¥æ³¨å†Œçš„æä¾›å•†
	providers := manager.ListProviders()
	if len(providers) == 0 {
		fmt.Println("âš ï¸ No LLM providers configured. Please set up API keys.")
		fmt.Println("   OpenAI: Set OPENAI_API_KEY environment variable")
		fmt.Println("   Hunyuan: Set HUNYUAN_API_KEY environment variable (format: secretId:secretKey)")
		return
	}

	fmt.Printf("ğŸ“‹ Available providers: %v\n", providers)

	// åˆ›å»ºæµ‹è¯•è¯·æ±‚
	req := &ChatRequest{
		Messages: []Message{
			{Role: "system", Content: "You are a helpful assistant."},
			{Role: "user", Content: "Hello! Please introduce yourself briefly."},
		},
		MaxTokens:   100,
		Temperature: 0.7,
	}

	ctx := context.Background()

	// æ¼”ç¤ºé˜»å¡å¼è°ƒç”¨
	fmt.Println("\nğŸ”„ Testing blocking chat...")
	resp, err := manager.ChatWithDefault(ctx, req)
	if err != nil {
		log.Printf("âŒ Chat error: %v", err)
	} else {
		if resp.Error != nil {
			log.Printf("âŒ API error: %s", resp.Error.Message)
		} else if len(resp.Choices) > 0 {
			fmt.Printf("âœ… Response: %s\n", resp.Choices[0].Message.Content)
		}
	}

	// æ¼”ç¤ºæµå¼è°ƒç”¨
	fmt.Println("\nğŸŒŠ Testing streaming chat...")
	eventChan, err := manager.StreamChatWithDefault(ctx, req)
	if err != nil {
		log.Printf("âŒ Stream chat error: %v", err)
		return
	}

	fmt.Print("ğŸ”¤ Streaming response: ")
	for event := range eventChan {
		if event.Error != nil {
			log.Printf("\nâŒ Stream error: %v", event.Error)
			break
		}

		if event.Data != nil {
			if event.Data.Error != nil {
				log.Printf("\nâŒ API error: %s", event.Data.Error.Message)
				break
			}

			if len(event.Data.Choices) > 0 && event.Data.Choices[0].Delta != nil {
				fmt.Print(event.Data.Choices[0].Delta.Content)
			}
		}

		if event.Done {
			fmt.Println("\nâœ… Stream completed")
			break
		}
	}

	// æ¸…ç†èµ„æº
	if err := manager.Close(); err != nil {
		log.Printf("âš ï¸ Failed to close manager: %v", err)
	}

	fmt.Println("\nğŸ‰ LLM demo completed!")
}
